<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><title>Neural message passing for quantum chemistry</title><meta http-equiv=onion-location content="http://kylrthjj7mpvktolz7u6fnudt3hpdvjw4hzquanjpepgsf5vcq5divad.onion/paper/neural-message-passing/"><meta property="og:title" content="Neural message passing for quantum chemistry"><meta name=twitter:title content="Neural message passing for quantum chemistry"><meta name=author content="Kyle Roth"><meta property="og:site_name" content="Kyle Roth"><meta property="og:url" content="https://kylrth.com/paper/neural-message-passing/"><meta name=twitter:card content="summary"><meta property="og:type" content="article"><meta name=generator content="Hugo 0.110.0"><link rel=stylesheet href=/css/style.min.css><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async>MathJax.Hub.Config({tex2jax:{inlineMath:[["\\(","\\)"]],displayMath:[["\\[","\\]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"}),MathJax.Hub.Config({TeX:{equationNumbers:{autoNumber:"AMS"}}})</script><script type=text/javascript src=/js/bundle.js></script></head><body><a href=#main class="skip-link p-screen-reader-text">Skip to content</a><svg xmlns="http://www.w3.org/2000/svg" style="display:none" aria-hidden="true"><symbol id="icon-permalink" viewBox="0 0 24 24"><g><path d="M0 0h24v24H0z" fill="none"/><path d="M3.9 12c0-1.71 1.39-3.1 3.1-3.1h4V7H7c-2.76.0-5 2.24-5 5s2.24 5 5 5h4v-1.9H7c-1.71.0-3.1-1.39-3.1-3.1zM8 13h8v-2H8v2zm9-6h-4v1.9h4c1.71.0 3.1 1.39 3.1 3.1s-1.39 3.1-3.1 3.1h-4V17h4c2.76.0 5-2.24 5-5s-2.24-5-5-5z"/></g></symbol><symbol id="icon-feed" viewBox="0 0 16 16"><g><path d="M2.13 11.733c-1.175.0-2.13.958-2.13 2.126.0 1.174.955 2.122 2.13 2.122a2.126 2.126.0 002.133-2.122A2.133 2.133.0 002.13 11.733zM.002 5.436v3.067c1.997.0 3.874.781 5.288 2.196a7.45 7.45.0 012.192 5.302h3.08c0-5.825-4.739-10.564-10.56-10.564zM.006.0v3.068C7.128 3.068 12.924 8.87 12.924 16H16C16 7.18 8.824.0.006.0z"/></g></symbol><symbol id="icon-github" viewBox="0 0 16 16"><g><path d="M8 .198A8 8 0 005.471 15.789c.4.074.547-.174.547-.385.0-.191-.008-.821-.011-1.489-2.226.484-2.695-.944-2.695-.944-.364-.925-.888-1.171-.888-1.171-.726-.497.055-.486.055-.486.803.056 1.226.824 1.226.824.714 1.223 1.872.869 2.328.665.072-.517.279-.87.508-1.07-1.777-.202-3.645-.888-3.645-3.954.0-.873.313-1.587.824-2.147-.083-.202-.357-1.015.077-2.117.0.0.672-.215 2.201.82A7.672 7.672.0 018 4.066c.68.003 1.365.092 2.004.269 1.527-1.035 2.198-.82 2.198-.82.435 1.102.162 1.916.079 2.117.513.56.823 1.274.823 2.147.0 3.073-1.872 3.749-3.653 3.947.287.248.543.735.543 1.481.0 1.07-.009 1.932-.009 2.195.0.213.144.462.55.384A8 8 0 008.001.196z"/></g></symbol><symbol id="icon-gitlab" viewBox="0 0 28 28"><g><path d="M1.625 11.031 14 26.89.437 17.046a1.092 1.092.0 01-.391-1.203l1.578-4.813zm7.219.0h10.313L14.001 26.89zM5.75 1.469l3.094 9.562H1.625l3.094-9.562a.548.548.0 011.031.0zm20.625 9.562 1.578 4.813a1.09 1.09.0 01-.391 1.203l-13.563 9.844 12.375-15.859zm0 0h-7.219l3.094-9.562a.548.548.0 011.031.0z"/></g></symbol><symbol id="icon-instagram" viewBox="0 0 22 22"><g><path d="M15.445.0H6.554A6.559 6.559.0 000 6.554v8.891A6.559 6.559.0 006.554 22h8.891a6.56 6.56.0 006.554-6.555V6.554A6.557 6.557.0 0015.445.0zm4.342 15.445a4.343 4.343.0 01-4.342 4.342H6.554a4.341 4.341.0 01-4.341-4.342V6.554a4.34 4.34.0 014.341-4.341h8.891a4.342 4.342.0 014.341 4.341l.001 8.891z"/><path d="M11 5.312A5.693 5.693.0 005.312 11 5.694 5.694.0 0011 16.688 5.694 5.694.0 0016.688 11 5.693 5.693.0 0011 5.312zm0 9.163a3.475 3.475.0 11-.001-6.95 3.475 3.475.0 01.001 6.95zm5.7-10.484a1.363 1.363.0 11-1.364 1.364c0-.752.51-1.364 1.364-1.364z"/></g></symbol><symbol id="icon-linkedin" viewBox="0 0 16 16"><g><path d="M6 6h2.767v1.418h.04C9.192 6.727 10.134 6 11.539 6 14.46 6 15 7.818 15 10.183V15h-2.885v-4.27c0-1.018-.021-2.329-1.5-2.329-1.502.0-1.732 1.109-1.732 2.255V15H6V6zM1 6h3v9H1V6zM4 3.5A1.5 1.5.0 11.999 3.499 1.5 1.5.0 014 3.5z"/></g></symbol><symbol id="icon-medium" viewBox="0 0 24 24"><g><path d="M22.085 4.733 24 2.901V2.5h-6.634l-4.728 11.768L7.259 2.5H.303v.401L2.54 5.594c.218.199.332.49.303.783V16.96c.069.381-.055.773-.323 1.05L0 21.064v.396h7.145v-.401l-2.52-3.049a1.244 1.244.0 01-.347-1.05V7.806l6.272 13.659h.729l5.393-13.659v10.881c0 .287.0.346-.188.534l-1.94 1.877v.402h9.412v-.401l-1.87-1.831a.556.556.0 01-.214-.534V5.267a.554.554.0 01.213-.534z"/></g></symbol><symbol id="icon-npm" viewBox="0 0 16 16"><g><path d="M0 0v16h16V0H0zm13 13h-2V5H8v8H3V3h10v10z"/></g></symbol><symbol id="icon-twitter" viewBox="0 0 16 16"><g><path d="M16 3.538a6.461 6.461.0 01-1.884.516 3.301 3.301.0 001.444-1.816 6.607 6.607.0 01-2.084.797 3.28 3.28.0 00-2.397-1.034A3.28 3.28.0 007.882 6.029 9.321 9.321.0 011.116 2.598a3.284 3.284.0 001.015 4.381A3.301 3.301.0 01.643 6.57v.041A3.283 3.283.0 003.277 9.83a3.291 3.291.0 01-1.485.057 3.293 3.293.0 003.066 2.281 6.586 6.586.0 01-4.862 1.359 9.286 9.286.0 005.034 1.475c6.037.0 9.341-5.003 9.341-9.341.0-.144-.003-.284-.009-.425a6.59 6.59.0 001.637-1.697z"/></g></symbol><symbol id="icon-vimeo" viewBox="0 0 16 16"><g><path d="M15.994 4.281c-.072 1.556-1.159 3.691-3.263 6.397-2.175 2.825-4.016 4.241-5.522 4.241-.931.0-1.722-.859-2.366-2.581-.431-1.578-.859-3.156-1.291-4.734-.478-1.722-.991-2.581-1.541-2.581-.119.0-.538.253-1.256.753l-.753-.969c.791-.694 1.569-1.388 2.334-2.081 1.053-.909 1.844-1.387 2.372-1.438 1.244-.119 2.013.731 2.3 2.553.309 1.966.525 3.188.647 3.666.359 1.631.753 2.447 1.184 2.447.334.0.838-.528 1.509-1.588.669-1.056 1.028-1.862 1.078-2.416.097-.912-.262-1.372-1.078-1.372a2.98 2.98.0 00-1.184.263c.787-2.575 2.287-3.825 4.506-3.753 1.641.044 2.416 1.109 2.322 3.194z"/></g></symbol><symbol id="icon-wordpress" viewBox="0 0 16 16"><g><path d="M2 8c0 2.313 1.38 4.312 3.382 5.259L2.52 5.622A5.693 5.693.0 002 8zm10.05-.295c0-.722-.266-1.222-.495-1.612-.304-.482-.589-.889-.589-1.371.0-.537.418-1.037 1.008-1.037.027.0.052.003.078.005A6.064 6.064.0 008 2.156 6.036 6.036.0 002.987 4.79c.141.004.274.007.386.007.627.0 1.599-.074 1.599-.074.323-.018.361.444.038.482.0.0-.325.037-.687.055l2.185 6.33 1.313-3.835-.935-2.495a12.304 12.304.0 01-.629-.055c-.323-.019-.285-.5.038-.482.0.0.991.074 1.58.074.627.0 1.599-.074 1.599-.074.323-.018.362.444.038.482.0.0-.326.037-.687.055l2.168 6.282.599-1.947c.259-.809.457-1.389.457-1.889zm-3.945.806-1.8 5.095a6.148 6.148.0 003.687-.093.52.52.0 01-.043-.081L8.105 8.511zm5.16-3.315c.026.186.04.386.04.601.0.593-.114 1.259-.456 2.093l-1.833 5.16c1.784-1.013 2.983-2.895 2.983-5.051a5.697 5.697.0 00-.735-2.803zM8 0a8 8 0 100 16A8 8 0 008 0zm0 15A7 7 0 118 1a7 7 0 010 14z"/></g></symbol><symbol id="icon-youtube" viewBox="0 0 16 16"><g><path d="M15.841 4.8s-.156-1.103-.637-1.587c-.609-.637-1.291-.641-1.603-.678-2.237-.163-5.597-.163-5.597-.163h-.006s-3.359.0-5.597.163c-.313.038-.994.041-1.603.678C.317 3.697.164 4.8.164 4.8S.005 6.094.005 7.391v1.213c0 1.294.159 2.591.159 2.591s.156 1.103.634 1.588c.609.637 1.409.616 1.766.684 1.281.122 5.441.159 5.441.159s3.363-.006 5.6-.166c.313-.037.994-.041 1.603-.678.481-.484.637-1.588.637-1.588s.159-1.294.159-2.591V7.39c-.003-1.294-.162-2.591-.162-2.591zm-9.494 5.275V5.578l4.322 2.256-4.322 2.241z"/></g></symbol><symbol id="icon-matrix" viewBox="0 0 28 28"><g><path d="M.975097.640961V27.359H2.89517V28H.238281V0H2.89517V.640961H.975097z"/><path d="M8.37266 9.11071V10.4628H8.4111C8.7712 9.94812 9.20494 9.54849 9.71306 9.26518 10.2208 8.98235 10.8029 8.84036 11.4586 8.84036 12.0885 8.84036 12.664 8.96298 13.1846 9.2074c.5208.24483.9163.67596 1.1864 1.2941C14.6665 10.0638 15.0683 9.67744 15.5764 9.34266 16.0842 9.00804 16.6852 8.84036 17.3797 8.84036 17.9069 8.84036 18.3953 8.90487 18.8457 9.03365c.4498.128769999999999.8355.33478 1.157.61801C20.3239 9.93515 20.5746 10.3053 20.755 10.7621c.1799.4575.27 1.0077.27 1.6518v6.6827H18.2861V13.4373C18.2861 13.1027 18.2734 12.7872 18.2475 12.4908 18.2216 12.1949 18.1512 11.9375 18.0354 11.7183 17.9196 11.4996 17.7491 11.3256 17.5243 11.1967 17.2993 11.0684 16.9938 11.0037 16.6081 11.0037c-.3856.0-.6975.0745000000000005-.9354.222C15.4346 11.374 15.2483 11.5673 15.1134 11.8052c-.135.2386-.225.508800000000001-.2699.8116C14.7982 12.9192 14.7759 13.2252 14.7759 13.5342v5.5624H12.0372V13.4955C12.0372 13.1994 12.0305 12.9063 12.0181 12.6168 12.005 12.3269 11.9506 12.0598 11.8539 11.815 11.7575 11.5706 11.5967 11.374 11.3717 11.2257 11.1467 11.0782 10.8156 11.0037 10.3785 11.0037 10.2497 11.0037 10.0794 11.0327 9.86746 11.0908 9.65528 11.1487 9.44941 11.2584 9.25027 11.4191 9.05071 11.5802 8.88053 11.812 8.73908 12.1143 8.59754 12.4171 8.5269 12.8128 8.5269 13.3021v5.7945H5.78833V9.11071H8.37266z"/><path d="M26.0246 27.359V.640961h-1.92V0h2.657V28h-2.657V27.359h1.92z"/></g></symbol></svg><header class=l-header><p class="c-title p-title"><a href=/ class=p-title__link>Kyl<span style=color:gray>e</span> R<span style=color:gray>o</span>th</a></p></header><main id=main class=l-main><article class=p-article><header><h1><a href=https://arxiv.org/abs/1704.01212>Neural message passing for quantum chemistry</a></h1><div><div class=c-time>Posted on
<time datetime=2022-03-25T14:46:11-04:00>2022-03-25 at 14:46:11 UTC-0400</time></div><a href=/tags/deep-learning/ class=c-tag>deep-learning</a>
<a href=/tags/simulation/ class=c-tag>simulation</a></div></header><section id=js-article class=p-article__body><p><em>This post was created as an assignment in Bang Liu&rsquo;s <a href=https://www-labs.iro.umontreal.ca/~liubang/IFT%206289%20-%20Winter%202022.htm>IFT6289</a> course in winter 2022. The structure of the post follows the structure of the assignment: summarization followed by my own comments.</em></p><p>To summarize, the authors create a unifying framework for describing message-passing neural networks, which they apply to the problem of predicting the structural properties of chemical compounds in the QM9 dataset.</p><h2 id=paper-summarization>paper summarization <a class=header-link href=#paper-summarization><svg class="c-links__icon"><title>permalink</title><use xlink:href="#icon-permalink"/></svg></a></h2><p>The authors first demonstrate that many of the recent works applying neural nets to this problem can fit into a message-passing neural network (MPNN) framework. Under the MPNN framework, at each time step <code>\(t\)</code> a message is computed for each vertex by summing the output of a learned function <code>\(M_t\)</code> over the vertex and all edges and vertices connected to it. Then the next state for each vertex is a learned function <code>\(U_t\)</code> of the previous state and the message. Finally, the &ldquo;readout&rdquo; function <code>\(R\)</code> is applied to all the vertices to compute the result.</p><p>It&rsquo;s important to note that the readout function <code>\(R\)</code> is expected to be invariant to the order of its inputs, meaning that it will be invariant to <a href=https://en.wikipedia.org/wiki/Cis%E2%80%93trans_isomerism>geometric isomerism</a>.</p><p>The authors acknowledge that the results they&rsquo;re approximating are themselves approximations, produced using a density functional theory (DFT) simulation, but they feel that &ldquo;it is hard to believe success on more challenging chemical tasks will be possible if we can&rsquo;t make accurate statistical predictions for the properties computed in QM9&rdquo; (section 4).</p><p>The authors start from the gated graph neural network (GG-NN) model as a baseline. For GG-NNs, the MPNN functions are the following:</p><div>\[M_t=A_{e_{vw}}h_w^t\]</div><div>\[U_t=\text{GRU}(h_v^t,m_v^{t+1})\]</div><div>\[R=\sum_{v\in V}\sigma\left(i(h_v^{(T)},h_v^0)\right)\cdot\left(j(h_v^{(T)})\right)\]</div><p>Where <code>\(A_{e_{vw}}\)</code> is a learned matrix for edge <code>\(e_{vw}\)</code>, and <code>\(i,j\)</code> are neural networks.</p><p>The authors attempt the following modifications to the GG-NN architecture. I&rsquo;ll mark each one that ended up in the best-performing model:</p><ul><li>message functions<ul><li>replace <code>\(A_{e_{vw}}\)</code> with <code>\(A(e_{vw})\)</code>, a neural network that creates a <code>\(d\times d\)</code> matrix from the edge vector <code>\(e_{vw}\)</code> (<strong>best performance</strong>)</li><li>allow the message from node <code>\(w\)</code> to node <code>\(v\)</code> to depend on <code>\(h_v\)</code> in addition to <code>\(h_w\)</code> and <code>\(e_{vw}\)</code></li><li><em>multiple towers</em>: propagate messages on subsets of the hidden states independently and then recombine with a neural mixing function</li></ul></li><li>&ldquo;virtual&rdquo; graph elements<ul><li>virtual edges between all nodes (<strong>best performance</strong>)</li><li>latent master node connected to all nodes</li></ul></li><li>readout function<ul><li><a href=https://arxiv.org/abs/1511.06391>set2set</a> (<strong>best performance</strong>)</li></ul></li><li>input representation<ul><li>represent hydrogen atoms as nodes instead of just including count as a feature of other nodes (<strong>best performance</strong>)</li><li>edge inputs:<ul><li>discrete bond types (single, double, triple, aromatic)</li><li>distance bins (discrete; highly correlated with bond type)</li><li>raw distance feature in addition to bond type (continuous; when message function allows; <strong>best performance</strong>)</li></ul></li></ul></li></ul><p>The resulting model outperformed all previous work by a large margin. The results were much stronger for models trained to predict one of the 13 desired metrics, rather than all 13 at once. On 11 of the 13 tasks, the results were better than <a href=https://chemistry.stackexchange.com/questions/62001/why-is-chemical-accuracy-defined-as-1-kcal-mol><em>chemical accuracy</em></a>, which is the target error expected by the chemistry research community.</p><h2 id=comments>comments <a class=header-link href=#comments><svg class="c-links__icon"><title>permalink</title><use xlink:href="#icon-permalink"/></svg></a></h2><p>From the second paragraph in section 8:</p><blockquote><p>We also found that training one model per target consistently outperformed jointly training on all 13 targets. In some cases the improvement was up to 40%.</p></blockquote><p>To me this sounds like an information bottleneck due to capacity. I imagine scaling up the model size would solve this problem. They theorized that the &ldquo;multiple towers&rdquo; method worked a bit like ensembling; maybe scaling that model large enough would solve the information bottleneck without unreasonable computational complexity.</p></section><footer><nav class="p-pagination c-pagination"><div class=c-pagination__ctrl><div class=c-pagination__newer><a href=/paper/experienced-well-being/>Newer</a></div><div class=c-pagination__older><a href=/paper/effect-of-model-size-on-worst-group-generalization/>Older</a></div></div></nav><section class=p-related><h3>See Also</h3><ul id=slider class=p-related__list><li class="p-related__item js-related__item"><a href=/paper/alphatensor/ style=background-image:url(/paper/alphatensor/strassen.png)><span>AlphaTensor: discovering faster matrix multiplication algorithms with reinforcement learning</span></a></li><li class="p-related__item js-related__item"><a href=/paper/whisper/ style=background-image:url(/paper/whisper/tokens.png)><span>Whisper: robust speech recognition via large-scale weak supervision</span></a></li><li class="p-related__item js-related__item"><a href=/paper/selective-annotation/ style=background-image:url(/paper/selective-annotation/step1.png)><span>Selective annotation makes language models better few-shot learners</span></a></li><li class="p-related__item js-related__item"><a href=/paper/dichotomous-data-difficulty/ style=background-image:url(/paper/dichotomous-data-difficulty/ddd.png)><span>Trivial or impossibleâ€”dichotomous data difficulty masks model differences (on ImageNet and beyond)</span></a></li><li class="p-related__item js-related__item"><a href=/paper/beyond_nsl/ style=background-image:url(/paper/beyond_nsl/pareto.png)><span>Beyond neural scaling laws: beating power law scaling via data pruning</span></a></li><li class="p-related__item js-related__item"><a href=/paper/locoprop/ style=background-image:url(/paper/locoprop/parallel.png)><span>LocoProp: enhancing backprop via local loss optimization</span></a></li></ul></section></footer></article></main><nav class="l-nav p-menu"><ul class=p-menu__lists><li class=p-menu__listitem><a href=/>homepage</a></li><li class=p-menu__listitem><a href=/post/>posts</a></li><li class=p-menu__listitem><a href=/paper/>paper notes</a></li><li class=p-menu__listitem><a href=/book/>book notes</a></li></ul></nav><footer class=l-footer><ul class=c-links><li class=c-links__item><a href=https://matrix.to/#/%40kyle%3akylrth.com target=_blank><svg viewBox="0 0 30 28" class="c-links__icon"><title>matrix</title><use xlink:href="#icon-matrix"/></svg></a></li><li class=c-links__item><a href=https://github.com/kylrth target=_blank><svg viewBox="0 0 64 64" class="c-links__icon"><title>github</title><use xlink:href="#icon-github"/></svg></a></li><li class=c-links__item><a href=https://www.linkedin.com/in/kyle-roth/ target=_blank><svg viewBox="0 0 64 64" class="c-links__icon"><title>linkedin</title><use xlink:href="#icon-linkedin"/></svg></a></li></ul><p class=p-copyright><a href=https://github.com/kylrth/kylrth.github.io/commits/4f5071599c5113539f2468ff0a6cd322b83b879c/content/paper/neural-message-passing.md>page
history</a></p></footer></body></html>