<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ai on Kyle Roth</title><link>https://kylrth.com/tags/ai/</link><description>Recent content in Ai on Kyle Roth</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 17 Apr 2025 13:19:47 -0400</lastBuildDate><atom:link href="https://kylrth.com/tags/ai/index.xml" rel="self" type="application/rss+xml"/><item><title>Speaking as from the Dust: ideologies of AI and digital resurrection in Mormon culture</title><link>https://kylrth.com/paper/speaking-as-from-the-dust/</link><pubDate>Wed, 08 May 2024 15:03:18 -0400</pubDate><guid>https://kylrth.com/paper/speaking-as-from-the-dust/</guid><description>&lt;p>I wrote this paper with Stephen Betts, a friend of mine doing Mormon Studies at the University of Virginia. (Click the title to download the preprint.) Our interest in the topic was initially piqued when we stumbled across the &lt;a href="https://wilfordwoodruffpapers.org/wilford-woodruff-ai-learning-experience">Wilford Woodruff AI Learning Experience&lt;/a>, and this paper explores the unique intersection of Mormonism, transhumanism, and machine learning that makes such a thing possible.&lt;/p>
&lt;p>We&amp;rsquo;re currently looking for a venue to publish this work. &lt;strong>Any feedback on the preprint is appreciated!&lt;/strong>&lt;/p></description></item><item><title>Better, Nicer, Clearer, Fairer: a critical assessment of the movement for ethical artificial intelligence and machine learning</title><link>https://kylrth.com/paper/better-nicer-cleaner-fairer/</link><pubDate>Tue, 24 Oct 2023 12:53:31 -0400</pubDate><guid>https://kylrth.com/paper/better-nicer-cleaner-fairer/</guid><description>&lt;p>&lt;em>I will present this paper in the FATE (fairness, accountability, transparency, ethics) reading group tomorrow (2023-10-25). You can view the slides I&amp;rsquo;ll use &lt;a href="https://docs.google.com/presentation/d/1Bl4Bfh-ryFfmsEVrmdnYBe69hKjZP4mYZppvZHU5-yM/edit?usp=sharing">here&lt;/a>.&lt;/em>&lt;/p>
&lt;p>There are unresolved tensions in the algorithmic ethics world. Here are two examples:&lt;/p>
&lt;ul>
&lt;li>Is inclusion always good?
&lt;ul>
&lt;li>Gebru: &amp;ldquo;you can&amp;rsquo;t have ethical A.I. that&amp;rsquo;s not inclusive&amp;hellip; [a]nd whoever is creating the technology is setting the standards&amp;rdquo;&lt;/li>
&lt;li>Nelson: &amp;ldquo;&amp;hellip; I struggle to understand why we want to make black communities more cognizant in facial recognition systems that are disproportionately used for surveillance.&amp;rdquo;&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>academic activism
&lt;ul>
&lt;li>O&amp;rsquo;Neil: why is there a lack of academic efforts to inform policymakers and regulators?&lt;/li>
&lt;li>PERVADE: Academics have been doing this work for a while but it is underfunded, marginalized, and at odds with a US political apparatus generally favorable towards Silicon Valley.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>Ethics manifestos or value statements mask these tensions behind a business ethics lens.&lt;/p></description></item></channel></rss>