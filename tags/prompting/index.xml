<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Prompting on Kyle Roth</title><link>https://kylrth.com/tags/prompting/</link><description>Recent content in Prompting on Kyle Roth</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Tue, 05 Nov 2024 10:03:08 -0500</lastBuildDate><atom:link href="https://kylrth.com/tags/prompting/index.xml" rel="self" type="application/rss+xml"/><item><title>InstructEval: systematic evaluation of instruction selection methods</title><link>https://kylrth.com/paper/instructeval/</link><pubDate>Mon, 25 Sep 2023 11:38:24 -0400</pubDate><guid>https://kylrth.com/paper/instructeval/</guid><description>&lt;p>&lt;em>This was a paper I presented about in Bang Liu&amp;rsquo;s research group meeting on 2023-09-25. You can view the slides I used &lt;a href="https://docs.google.com/presentation/d/1Qo_KPNnkj2jQzYDKG1wSEisHAr18Fs_eHq5Iuzj0MNs/edit?usp=sharing">here&lt;/a>.&lt;/em>&lt;/p></description></item><item><title>Selective annotation makes language models better few-shot learners</title><link>https://kylrth.com/paper/selective-annotation/</link><pubDate>Tue, 13 Sep 2022 11:26:21 -0400</pubDate><guid>https://kylrth.com/paper/selective-annotation/</guid><description>&lt;p>Selective annotation chooses a pool of samples to annotate from a large set of unlabeled data. The main result of the paper is that when this is combined with item-specific prompt retrieval the performance drastically improves (&amp;gt;10% relative gain and lower performance variance). Interestingly, selective annotation does &lt;em>not&lt;/em> help for finetuning, or when the prompts are randomly selected. They call their selective annotation method &amp;ldquo;vote-&lt;code>\(k\)&lt;/code>&amp;rdquo;.&lt;/p>
&lt;h2 id="selective-annotation-method">selective annotation method &lt;a class="header-link" href="#selective-annotation-method">&lt;svg class="c-links__icon">&lt;title>permalink&lt;/title>&lt;use xlink:href="#icon-permalink">&lt;/use>&lt;/svg>&lt;/a>&lt;/h2>
&lt;p>Vote-&lt;code>\(k\)&lt;/code> essentially creates a network of similar&lt;span class="sidenote-number">&lt;small class="sidenote">according to Sentence-BERT&lt;/small>&lt;/span>
unlabeled instances, and then selects from them with a network importance score that is discounted to promote diversity&lt;span class="sidenote-number">&lt;small class="sidenote">The discounting is performed by iteratively adding to the selection set, each time penalizing new nodes for being close to nodes that are already in the selection set.&lt;/small>&lt;/span>
.&lt;/p></description></item></channel></rss>